# Запускаем ClickHouse своими силами и радуемся скорости и аналитическим возможностям

В статье описан простой и проверенный путь для тех, кто хочет **внедрить аналитическую СУБД [ClickHouse](https://clickhouse.yandex/) своими силами** или просто опробовать ClickHouse на собственных данных. Именно этот путь мы прошли сами в компании СМИ2.

В предисловии статьи — небольшой рассказ о наших попытках внедрить Druid и InfluxDB. Почему после успешного запуска ClickHouse мы смогли отказаться от использования InfiniDB и Cassandra. 

Основная часть статьи посвящена [продуктам-помощникам для работы с ClickHouse](https://github.com/smi2), которые мы сами разработали и выпустили в open-source. 

Кстати, добро пожаловать в pull requests с предложениями и замечаниями.

Предполагаем, что читатель знаком с [официальной документацией ClickHouse](https://clickhouse.yandex/reference_ru.html).

### Кто мы такие и с какими данными работаем

В начале — о том, кто мы такие и с какими данными работаем. На примере одного из набора наших данных мы и будем далее разбирать работу с ClickHouse.

СМИ2 —  информационный сервис, который с 2007 года круглосуточно поставляет актуальные новости и формирует полноценную информационную картину дня. На сегодняшний день СМИ2 включает в себя новостной агрегатор и [партнёрскую сеть](https://smi2.net/corporate/traffic/) с более чем 2500 участников, среди которых: ресурсы федерального уровня, отраслевые сайты и региональные издания. Месячная аудитория СМИ2 составляет порядка 15 млн человек.

Мы будем разбирать работу с ClickHouse на примере данных, собираемых с нашего **новостного агрегатора**, который представлен тремя региональными сайтами: [smi2.ru](http://smi2.ru/), [smi2.ua](https://smi2.ua/) и [smi2.kz](http://smi2.kz/). На каждом сайте мы собираем и обрабатываем данные о просмотрах и кликах по новостям. Эти данные используются как в режиме реального времени — для выдачи контента, так и для постанализа эффективности материалов.

В вашем случае анализируемыми данными могут быть, например: логи сервера, статистика по событиям на сайтах, в системах бронирования, электронной рассылки, отслеживания показаний датчиков и т. п. Во всех этих случаях ClickHouse стоит того, чтобы попробовать.

### Как мы пришли к ClickHouse

Мы определили для себя следующие критические требования к аналитической СУБД:

* скорость обработки запросов в режиме реального времени,
* наличие встроенных аналитических функций,
* наличие функций для приближённых вычислений,
* линейная масштабируемость, т. к. добиться линейной масштабируемости без деградации с ростом числа серверов — сложнейшая техническая задача,
* наличие механизмов шардирования и репликации данных «из коробки»,
* отсутствие единой точки отказа; в каждый узел в кластере можно писать данные

В качестве предыстории хотелось бы рассказать о том, какой технологический стек мы использовали ранее, от чего пришлось отказаться, и как мы пришли к ClickHouse.

#### Неудачный опыт с Druid и InfluxDB


Ссылки: 
[http://druid.io/](http://druid.io/)  [https://imply.io/product](https://imply.io/product) https://github.com/druid-io/tranquility



В этом году мы развернули druid.io, сборку Imply Analytics Platform от imply.io, и уже приготовились запускать в продакшн, но…


Из плюсов отметили для себя следующее:

* Поддержка RT stream из HTTP, Spark, Kafka и т. д.
* Графические инструменты Pivot, Caravel 

Однако следующие недостатки перевесили чашу весов, и мы, в итоге, отказались от запуска Druid:

* Сложность инфраструктуры: требуются отдельные ноды для получения, обработки и хранения данных, для отказоустойчивости держать по 2x нод 
* Tranquility, предназначенный для realtime обработки данных, содержит ошибки, приводящие к падению всего Tranquility; версии Tranquility несовместимы между собой; Оцениваем состояние Tranquility как Beta-версия, хороший интересный продукт но пока в состоянии Beta   

Также у нас был пробный подход к InfluxDB [http://influxdata.com/](http://influxdata.com/) + https://habrahabr.ru/company/selectel/blog/245515/, которую мы планировали использовать для построения и анализа метрик. Проект мы оценили для себя как глубокую Alfa из-за частых потерь данных и падений системы, поэтому это направление мы тоже решили свернуть. Возможно сейчас состояние продукта изменилось в лучшую сторону.

#### Cassandra и InfiniDB продержались у нас два года

Cassandra использовалась у нас в продакшне с 2014 по 2016 год:  

* Работала на 5 серверах
* Выдерживала нагрузку до 10К событий в секунду на вставку и примерно до 1К событий в секунду на чтение
* Примерно 1 раз в 2 месяца случались рассинхронизации схем данных

В этот же период мы использовали и InfiniDB [https://github.com/infinidb/infinidb](https://github.com/infinidb/infinidb) . Из положительных моментов хотелось бы отметить такие:

* Поддержка оконных функций   
* Простота интеграции с существующим MySQL через движок Federated
* Встроенный движок MyISAM и InnoDB, что позволяет делать выгрузки из движка InfiniDB в движок InnoDB внутри одного сервера 
* Возможность удаление партиций данных по каждому дню, по определенным колонкам

Однако не обошлось и без негативных моментов:

* Отсутствие нормального кластера и репликации данных. Приходилось делать горячую копию данных, т. е. клон сервера
* Первые версии приходилось регулярно перегружать из-за утечек памяти и зависаний сервиса
* Зависания процессов на запись или запросов на чтение. Пришлось убивать долгие процессы через event handlers nagios
* Сложность загрузки данных. Есть только отдельный консольный инструмент cpimport. Пришлось реализовывать обёртку, которая разбирает STDOut на  ошибки и статистику результата выполнения вставки
* Условная однопоточность: или пишем, или читаем. Потребляется большой объём системных ресурсов

### И тут «Яндекс» выложил в открытый доступ ClickHouse 

В общем, недостатков и проблем с используемыми у нас для аналитики СУБД было достаточно. Поэтому мы регулярно смотрели по сторонам в поисках альтернатив. В том числе мы обратили внимание на внутреннюю разработку «Яндекса», которая подкупала своей невероятной скорострельностью и в целом соответствовала нашим ожиданиям от аналитической СУБД (см. выше).

В настоящий момент на рынке нет аналитических баз данных дешевых или бесплатных для обработки больших данных в режиме реального времени уровня, подобного ClickHouse, или мы не знаем об этом — дополнительно были тесты из платных — это HP Vercia и greenplum . Аналитику можно считать и на MapReduce на Hadoop, но не в режиме, близком к режиму реального времени. Кстати, в самом «Яндексе» есть YT («Ыть», как они сами её называют) — именно MapReduce-платформа для работы с большими данными, но она тоже не работает в режиме реального времени, хотя активно используется. То есть ClickHouse больше всего подходит для аналитики в режиме реального времени.

Поэтому, когда «Яндекс» опубликовал летом ClickHouse в открытом доступе, мы однозначно решили его попробовать.


@todo links:

CH - https://habrahabr.ru/company/yandex/blog/273305/

YT - https://events.yandex.ru/lib/talks/4103/

CH - https://habrahabr.ru/company/yandex/blog/303282/

## Как нам помог ClickHouse

Можно однозначно утверждать, что процесс запуска ClickHouse прошёл у нас быстрее и проще, чем с другими СУБД. Надеемся, что наша статья позволит вам сделать это существенно быстрее :)

Если промотать историю о том, как мы запускали ClickHouse и, в итоге, успешно запустили, то стоит отметить следующие результаты запуска ClickHouse.

**Выгоды в разработке**.  В относительно короткий срок нам удалось закрыть 80 % задач, связанных с анализом данных, а этих задач накопилось много. Новые задачи по аналитике стали выполняться гораздо проще и быстрее.

**Выгоды в железе**. По сравнению с тем же Druid, требования к железу у ClickHouse оказались существенно ниже, поэтому нам удалось сэкономить на железе. Плюс мы отказались от 5 нод под Cassandra, от 4 нод под InfiniDB и от 2 нод MySQL (исторически оставшейся аналитики). Итого мы отказались от 11 серверов, за которыми нужно было постоянно присматривать и не пропускать алерты от nagios об их проблемах.

**Выгоды в хранении данных**. ClickHouse умеет хранить данные более компактно и размазано по нескольким серверам, в отличие от InfiniDB.

**Выгоды в скорости**. ClickHouse реально быстрый, мы убедились в этом на своих задачах, скорость возросла в несколько раз!

Здесь многие подумают, что неплохо было бы привести для примера бенчмарки… Предлагаем обратиться к [бенчмаркам «Яндекса»](https://clickhouse.yandex/benchmark.html) и посмотреть наши ролики с запросами на реальных наборах данных.

Добавить видосы Игоря с краткими описания.

Статистика собираемых и анализируемых нами с помощью ClickHouse  данных на текущий момент такова:

* Регистрируем до 8 000—12 000 событий в секунду
* приблизительно 21,5 млрд событий за месяц
* примерно 10 млрд строк в базе за месяц

Данные хранятся на 6ти серверах SX131 от Hetzner -  из которых  : три шарда и три это реплики, 

## Особенности ClickHouse

Как у любого продукта для работы с данными, у ClickHouse есть свои особенности. Вот некоторые из них : 

* Отсутствие UPDATE и производных: INSERT UPDATE и DELETE
* Отсутствие транзакционности
* Удаление данных по месяцу через удаление партиций

О них [пишет сам «Яндекс»](https://clickhouse.yandex/reference_ru.html#Особенности%20ClickHouse,%20которые%20могут%20считаться%20недостатками), и в планах Яндекса добавить возможность удаление партиций по дням.

Кроме этого, ClickHouse не умеет строить графики «из коробки»: для этого нужны дополнительные инструменты хотя бы уровня Pivot.

Для нас не принципиальна транзакционность и UPDATE/DELETE — мы давно привыкли обходить эти проблемы — но очень хотелось бы иметь возможность хранить данные только за несколько дней.

## Наши проекты для ClickHouse

В процессе освоения и внедрения ClickHouse мы столкнулись с некоторыми неудобствами и отсутствием нужных нам «плюшек». Поэтому, не став ждать милостей от «Яндекса» природы, мы решили облегчить себе работу сами. Ещё одним мотиватором было то, что нам хотелось внести свой вклад в развитие молодого, но перспективного open-source проекта. Плюс это был наш первый опыт участия в open-source разработке.

Так родились наши два open-source проекта, которые позволили нам самим существенно ускорить и упростить процесс внедрения ClickHouse и работу с ним: 

1. [Графический клиент](https://github.com/smi2/clickhouse-frontend) для работы с БД

2. [Обёртка на PHP](https://github.com/smi2/phpClickHouse) для удобной работы с БД, реализующая возможности ClickHouse

Ниже описаны основные возможности каждого проекта.

### Наш графический клиент для ClickHouse: возможности и особенности

* Просмотр списка баз данных и таблиц
* Просмотр содержания таблицы
* Подсветка функций ClickHouse, названий таблиц и полей 
* Автодополнение для названий таблиц, колонок и встроенных функций
* Выполнение выделенного / текущего / нескольких запросов в редакторе 
* Автоматическое определение типа запроса: CREATE TABLE / INSERT / SELECT   
* Удобная вставка словарей 
* Темы для редактора запросов, тема оформления всего редактора светлая/темная 
* Горячие клавиши

Клиент написан полностью на JavaScript, без использования server side.

Вы можете спокойно использовать наш последний опубликованный билд [http://guiclickhouse.smi2.ru/](http://guiclickhouse.smi2.ru/).


@todo insert video:

https://monosnap.com/file/rIEnBkDoh0jMmhGDsu0umaqk5F0srt


### Наш PHP-драйвер для ClickHouse: возможности и особенности
* Отсутствие зависимостей, требуются только модули curl и json
* Работа с кластером ClickHouse, автоматическое определение необходимых node при разных конфигурациях
* Выполнение запроса на каждой node в кластере (см. наш [отдельный проект, посвященный миграциям на ClickHouse](https://github.com/smi2/phpMigrationsClickhouse))
* Асинхронное выполнение запросов на чтение данных и вставку данных 
* Поддержка сжатия на лету при записи данных в ClickHouse из локального файла, без создания временных файлов
* Поддержка запросов на чтение с использованием локального InsertRow-файла, для выполнения запроса вида select * from X where id in (local_csv_file)
* Работа с партициями таблиц
* Вставка массива в колонку
* Запись результата запроса напрямую в файл, с поддержкой сжатия без создания временных файлов
* Получение размера таблицы, базы и списка процессов на каждой node
* Получение статистики выполнения запроса SELECT

Драйвер протестирован на PHP 5.6 и 7, HHVM 3.9.

**Оговорки:  засунуть под споллер - Оговорки : **

Cтоит сразу оговориться, драйвер не использует готовые решение в виде guzzle/PSR-7 и PSR-4: Autoloader реализован через файл include.php - надеюсь вас это не отпугнет от последующего прочтения      

## Примеры работы с ClickHouse

Рассмотрим на примере наших данных, как работать ClickHouse [из PHP](https://github.com/smi2/phpClickHouse) и с помощью нашего [графического клиента](https://github.com/smi2/clickhouse-frontend).

Считаем, что вы успешно установили ClickHouse из deb-пакета последней версии и ознакомились с Quick start guide https://clickhouse.yandex/tutorial.html.

Имеем список наших сайтов.

<table>
  <tr>
    <td>site_id</td>
    <td>Домен</td>
  </tr>
  <tr>
    <td>1</td>
    <td>smi2.ru</td>
  </tr>
  <tr>
    <td>2</td>
    <td>smi2.ua</td>
  </tr>
  <tr>
    <td>3</td>
    <td>smi2.kz</td>
  </tr>
</table>


На каждом сайте совершаются события, связанные со статьями (новостями). 
Мы будем регистрировать данные о показах статей (views) и кликах по каждой статье (clicks).

По каждому событию мы будем фиксировать несколько атрибутов:
* IP-адрес пользователя
* город пользователя
* referer
* UTM-метку из referer
* уникальный ID пользователя

 

### Подключение к серверу ClickHouse, создание БД и таблицы

Для записи данных о событиях создадим на сервере ClickHouse базу данных articles и внутри неё таблицу events со следующей структурой:

```sql
event_date Date
event_time DateTime
event_type Enum8('VIEWS' = 1, 'CLICKS' = 2)
site_id Int32
article_id Int32
ip String
city String
user_uuid String
referer String
utm String
```
Сначала рассмотрим создание базы данных и таблицы с помощью нашего **графического клиента**. Подключаемся через графический клиент к серверу ClickHouse и [выполняем запрос на создание новой базы данных и новой таблицы](https://monosnap.com/file/jXQ69WRy8cOyu2KJTlMSYOY32bMsQO):  
```sql
CREATE DATABASE articles
;;
CREATE TABLE articles.events (
    event_date Date,
    event_time DateTime,
    event_type Enum8('VIEWS' = 1, 'CLICKS' = 2),
    site_id Int32,
    article_id Int32,
    ip String,
    city String,
    user_uuid String,
    referer String,
    utm String
) ENGINE = MergeTree(event_date, (site_id, event_date, article_id), 8192)
```

Поясним некоторые параметры этого запроса:

* MergeTree — это движок таблицы. Также существуют Log, CollapsingMergeTree, SummingMergeTree, ReplacingMergeTree и другие. 

* Первый параметр event_date указывает на имя столбца типа Date, содержащего дату.

* (site_id, event_date, article_id) — кортеж, определяющий первичный ключ таблицы ( индекс ).

В большинстве запросов на чтение планируется указывать, по какому сайту нам нужны данные, поэтому первым в индексе используется site_id.

Теперь попробуем создать подключение к серверу ClickHouse, базу данных и таблицу через наш **драйвер PHP**. Для этого сначала установим драйвер. 

Можно установить несколькими вариантами:

# через composer:

`composer require smi2/phpclickhouse`

# через Git (мы в production используем ветку master):

git clone [https://github.com/smi2/phpClickHouse.git](https://github.com/smi2/phpClickHouse.git)

В случае установки через Git подключаем драйвер:

`include_once 'phpClickHouse/include.php';`

Описание всех функций и ChangeLog опубликованны в Github. 

Теперь выполняем запрос на подключение к серверу, создание БД и таблицы:
```php
<?php

// Конфигурация
$config = [
    'host'     => '192.168.1.20',
    'port'     => '8123',
    'username' => 'default',
    'password' => ''
];

// Создаем клиента
$client = new \ClickHouseDB\Client($config);

// Проверяем соединение с базой
$client->ping();

// Отправляем запрос на создание
$client->write('CREATE DATABASE IF NOT EXISTS articles');
$client->write("
    CREATE TABLE IF NOT EXISTS articles.events (
        event_date Date,
        event_time DateTime,
        event_type Enum8('VIEWS' = 1, 'CLICKS' = 2),
        site_id Int32,
        article_id Int32,
        ip String,
        city String,
        user_uuid String,
        referer String,
        utm String
    ) ENGINE = MergeTree(event_date, (site_id, event_date, article_id), 8192)
");

// Выбираем default базу
$client->database('articles');

// Получаем список таблиц
print_r($client->showTables());
```


Обращаем внимание, что запросы в драйвере разделены на следующие:
* запись 
* вставку данных 
* чтение

 

Чтение и вставка могут быть асинхронными, то есть параллельно может выполняться несколько запросов.

Запросы на запись и вставку данных не содержат ответа, выполняется только проверка того, что ответ сервера был положительным. Запросы на чтение ответ содержат, исключением является прямая запись ответа в файл.

## Вставка данных, в том числе из InsertRow-файла

Вставим данные, которые будем использовать для тестирования:
```php
$client->insert(
    'events',
    [
        [date('Y-m-d'), time(), 'CLICKS', 1, 1234, '192.168.1.1', 'Moscow', 'xcvfdsazxc', '', ''],
        [date('Y-m-d'), time(), 'CLICKS', 1, 1235, '192.168.1.1', 'Moscow', 'xcvfdsazxc', 'http://yandex.ru', ''],
        [date('Y-m-d'), time(), 'CLICKS', 1, 1236, '192.168.1.1', 'Moscow', 'xcvfdsazxc', '', ''],
        [date('Y-m-d'), time(), 'CLICKS', 1, 1237, '192.168.1.1', 'Moscow', 'xcvfdsazxc', '', ''],
    ],
    ['event_date', 'event_time', 'event_type', 'site_id', 'article_id', 'ip', 'city', 'user_uuid', 'referer', 'utm']
);
```
Такой метод вставки подходит только для маленьких таблиц или таблиц справочников, т.к. заставляет PHP перегонять массив в строку.  

Получим результат вставки данных:
```php
print_r(
    $client->select('SELECT * FROM events')->rows()
);
```
Подробнее про чтение данных написано ниже.

Для вставки большего количества строк воспользуемся **прямой загрузкой InsertRow-файла**, который будет генерироваться при событии. Для этого будем записывать InsertRow-файл на сервере, где происходят события, и, для упрощения, отправлять его оттуда сразу в ClickHouse.

Допустим, что у нас есть некий класс UserEvent, который позволяет получить все необходимые данные для вставки, данные проверены на валидность внутри класса:
```php
$row = [
    'event_date'  => $userEvent->getDate(),
    'event_time'  => $userEvent->getTime(),
    'event_type'  => $userEvent->getType(),
    'site_id'     => $userEvent->getSiteId(),
    'article_id'  => $userEvent->getArticleId(),
    'ip'          => $userEvent->getIp(),
    'city'        => $userEvent->getCity(),
    'user_uuid'   => $userEvent->getUserUuid(),
    'referer'     => $userEvent->getReferer(),
    'utm'         => $userEvent->getUtm(),
];
```

Запись будем производить в файл, ротируемый ежеминутно, следующим способом (допускаем все недостатки: ошибки записи, блокировки, и т. д. — строка всегда записывается):    
```php
$fp = fopen('/tmp/articles.events_version1_' . date('YmdHi') . '.csv', 'w');
fputcsv($fp, $row);
fclose($fp);
```
В примере на GitHub, для тестов, сделан эмулятор класса UserEvent и file_put_contents.

Допустим, что у нас накопилось 5—10 таких файлов, и мы хотим их отправить в базу:

```php
$fileNames = [
    '/tmp/articles.events_version1_201612121201.csv',
    '/tmp/articles.events_version1_201612121301.csv',
    '/tmp/articles.events_version1_201612121401.csv',
];

// Включаем сжатие
$client->enableHttpCompression(true);
$insertResult = $client->insertBatchFiles('events', $fileNames, [
    'event_date', 'event_time', 'event_type', 'site_id', 'article_id', 'ip', 'city', 'user_uuid', 'referer', 'utm'
]);

// Можем получить время, за которое данные были доставлены
foreach ($fileNames as $fileName) {
    echo $fileName . ' : ' . $insertResult[$fileName]->totalTimeRequest() . "\n";
}
```


При больших объёмах вставляемых из файлов данных включаем режим сжатия. В этом случае используется потоковое сжатие, без создания временных файлов, что позволяет экономить на сетевых ресурсах сервера, немного увеличивая нагрузку на CPU. Следовательно скорость передачи данных возрастает, и суммарное время, затраченное на обработку одного файла, уменьшается в несколько раз.

В нашем примере для каждой строки мы передаем поле event_date, хотя эта же дата передаётся в поле event_time. Можно сэкономить ресурсы и не передавать каждый раз поля, которые можно вычислить из другого поля  на сервере ClickHouse. Подробнее о **значениях по умолчанию** см. в [документации по ClickHouse](https://clickhouse.yandex/reference_ru.html#Значения%20по%20умолчанию).

Поле utm будем заполнять из поля referer, если в нём указан utm_campaign:

через ф-цию extractURLParameter(referer, ’utm_campaign’)

Пересоздадим таблицу:
```sql
CREATE TABLE articles.events (
    event_date Date DEFAULT toDate(event_time),
    event_time DateTime,
    event_type Enum8('VIEWS' = 1, 'CLICKS' = 2),
    site_id Int32,
    article_id Int32,
    ip String,
    city String,
    user_uuid String,
    referer String,
    utm String DEFAULT extractURLParameter(referer,'utm_campaign')
) ENGINE = MergeTree(event_date, (site_id, event_date, article_id), 8192)
```

Изменим запись:

@TODO:**Убрать под споллер**
```php
$client->insert(
    'events',
    [
        [time(), 'CLICKS', 1, 1234, '192.168.1.11', 'Moscow',   'user_11', ''],
        [time(), 'CLICKS', 1, 1235, '192.168.1.11', 'Moscow',   'user_11', 'http://yandex.ru?utm_campaign=abc'],
        [time(), 'CLICKS', 1, 1236, '192.168.1.11', 'Moscow',   'user_11', 'http://smi2.ru?utm_campaign=abc'],
        [time(), 'CLICKS', 1, 1237, '192.168.1.11', 'Moscow',   'user_11', ''],
        [time(), 'CLICKS', 1, 1237, '192.168.1.13', 'Moscow',   'user_13', ''],
        [time(), 'CLICKS', 1, 1237, '192.168.1.14', 'Moscow',   'user_14', ''],
        [time(), 'VIEWS',  1, 1237, '192.168.1.11', 'Moscow',   'user_11', ''],
        [time(), 'VIEWS',  1, 1237, '192.168.1.12', 'Moscow',   'user_12', ''],
        [time(), 'VIEWS',  1, 1237, '192.168.1.1',  'Rwanda',   'user_55', 'http://smi2.ru?utm_campaign=abc'],
        [time(), 'VIEWS',  1, 1237, '192.168.1.1',  'Banaadir', 'user_54', 'http://smi2.ru?utm_campaign=abc'],
        [time(), 'VIEWS',  1, 1237, '192.168.1.1',  'Tobruk',   'user_32', 'http://smi2.ru?utm_campaign=CM1'],
        [time(), 'VIEWS',  1, 1237, '192.168.1.1',  'Gisborne', 'user_12', 'http://smi2.ru?utm_campaign=CM1'],
        [time(), 'VIEWS',  1, 1237, '192.168.1.1',  'Moscow',   'user_43', 'http://smi2.ru?utm_campaign=CM3'],
    ],
    ['event_time', 'event_type', 'site_id', 'article_id', 'ip', 'city','user_uuid','referer']
);
```

### Чтение данных

Меньше слов — больше кода!.. Приведём простой пример, как два запроса выполняются параллельно через драйвер:
```php
$state1 = $db->selectAsync('SELECT 1 as ping');
$state2 = $db->selectAsync('SELECT 2 as ping');

// Отправка запросов в CH
$db->executeAsync();

// Результат
print_r($state1->rows());
print_r($state2->rows());
```

Или вариант без асинхронности:
```php
$statement = $db->select('SELECT 33 as ping'); 
```

Результат запросов — это объект Statement, который умеет делать следующее:
```php
// Посчитать количество строк в результирующем наборе 
$statement->count();

// Посчитать, не менее скольких строчек получилось бы, если бы не было LIMIT-а или rows_before_limit_at_least
$statement->countAll();

// Получить первую строку ответа как массив 
$statement->fetchOne();

// Получить тотальные значения, если в запросе SELECT используется WITH TOTALS
print_r($statement->totals());

// Получить все строки в виде массива 
print_r($statement->rows());

// Получить суммарное время, потраченное на соединение с базой и получение ответа, данные из curl
print_r($statement->totalTimeRequest());

// Получить полный ответ curl_info 
print_r($statement->responseInfo());

// Получить информацию о выполнении запроса предоставленные CH  
print_r($result->statistics());
```


Попробуем прочитать наши данные. 

Допустим, нам нужно посчитать, сколько уникальных пользователей просмотрело статьи по дням:
```sql
SELECT 
    event_date,
    uniqCombined(user_uuid) AS count_users
FROM
    events
GROUP BY
    event_date
ORDER BY
    event_date
```

Сколько пользователей, которые просматривали статьи, совершили клики: 
```sql
SELECT 
    user_uuid,
    count() AS clicks
FROM 
    articles.events
WHERE
    event_type = 'CLICKS'
    AND user_uuid IN (
        SELECT
            user_uuid
        FROM
            articles.events
        WHERE
            event_type = 'VIEWS'
        GROUP BY
            user_uuid
    )
GROUP BY
    user_uuid
```

Посчитаем ботов, сделав грубую оценку через количество запросов с одного IP и количество во уникальных ID пользователей:
```sql
/* показывать в отчёте только IP, по которым было хотя бы 4 уникальных посетителей. */
SELECT
    ip,
    uniqCombined(user_uuid) AS count_users
FROM
    events
WHERE
    event_date = today()
GROUP BY
    ip
HAVING
    count_users >= 4
```


Какие UTM-метки давали большее количество показов:
```sql
SELECT
    utm,
    count() AS views FROM events
WHERE
    event_date = today()
    AND event_type = 'VIEWS'
    AND utm <> ''
GROUP BY
    utm
ORDER BY
    views DESC
```

### Использование внешних данных для обработки запроса

Допустим, что нам нужно посчитать, *сколько уникальных пользователей просмотрело за сутки статьи X*, где в X перечислено несколько идентификаторов статей. Это можно сделать так: 

`WHERE articles_id IN (1,2,3,4,5,6,7,8,9)`

И в данном примере это будет прекрасно работать. 
Но что делать, если таких идентификаторов тысячи или десятки тысяч? В этом случае можно использовать, функционал CH  [внешние данные для обработки запроса](https://clickhouse.yandex/reference_ru.html#Внешние%20данные%20для%20обработки%20запроса).



Рассмотрим эту возможность ClickHouse на примере. 

Создадим InsertRow-файл `'/tmp/articles_list.csv'`, в котором перечислим все нужные для запроса `article_id` и попросим ClickHouse создать временную таблицу `namex`, содержащую одну колонку:
```php
$whereIn = new \ClickHouseDB\WhereInFile();
$whereIn->attachFile(
    '/tmp/articles_list.csv', 'namex', ['article_id' => 'Int32'], \ClickHouseDB\WhereInFile::FORMAT_CSV
);

// Тогда содержимое файла InsertRow можно использовать на сервере:
$sql = 'Написать пример запроса';
$result = $db->select($sql, [], $whereIn);
```



На этом мы, пожалуй, завершим первую часть нашего рассказа о ClickHouse. Если у вас есть замечания или вы нашли ошибки, опечатки — добро пожаловать в мир open-source, будем ждать ваших pull request по этой статье: [https://github.com/smi2/phpClickHouse/blob/master/doc/01_article.md](https://github.com/smi2/phpClickHouse/blob/master/doc/01_article.md)

Если вы любите анализ данных, и вам интересно поработать с данными и ClickHouse — добро пожаловать к нам в команду ;)

## Что дальше

Мы планируем сделать цикл материалов, посвящённых нашему опыту работы с ClickHouse. В планах — следующие темы.

#### Часть 2:
* Подключение к кластеру ClickHouse из PHP 
* Отправка запросов в кластер, реализация миграций на PHP
* Семплирование данных в ClickHouse 

#### Часть 3:
* Использование словарей из MySQL в ClickHouse
* Движки таблиц: CollapsingMergeTree, SummingMergeTree, MaterializedView

#### Часть 4:
* Примеры запросов в ClickHouse на открытых данных СМИ2
* Семплирование данных в Clickhouse
* Сравнение с InifiniDB
